---
title: "total_cn"
author: "CGA"
date: "November 25, 2017"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Load necessary packages
library(tidyverse)
library(readxl)
library(reshape2)
library(zoo)
# Set working directory
setwd("~/east-river/")
```

## Load total CN data, sample descriptors, column names
```{r}
#er_bulk <- read.table("Data/EA_Data/CA_ER_bulk_6Nov2017.txt", sep="\t") #out of order, corrected below
er_heavy <- read.table("Data/EA_Data/CA_ER_heavy_7Nov2017.txt", sep="\t")
er_bulk_ed <- read_excel("Data/EA_Data/CA_ER_bulk_6Nov2017_corrected.xlsx")[,-(1:4)]
er_int <- read.table("Data/EA_Data/CA_ER_int_10Nov2017.txt", sep="\t")

# Adding column names
colnames(er_heavy) <- c("full_name", "instrument_name", "sample", "sample_id", "sample_amt", 
  "N_ret_min", "N_resp", "N_wt_mg", "N_wt_pct", "N_peaktype", "N_element_name", "N_C_resp_ratio", 
  "C_ret_min", "C_resp", "C_wt_mg", "C_wt_pct", "C_peaktype", "C_element_name", "C_C_resp_ratio")

colnames(er_int) <- c("full_name", "instrument_name", "sample", "sample_id", "sample_amt", 
  "N_ret_min", "N_resp", "N_wt_mg", "N_wt_pct", "N_peaktype", "N_element_name", "N_C_resp_ratio", 
  "C_ret_min", "C_resp", "C_wt_mg", "C_wt_pct", "C_peaktype", "C_element_name", "C_C_resp_ratio")

# Split fraction and sample name
er_heavy <- er_heavy %>%
  separate(sample_id, c("fraction", "sample-rep"), "_")

er_int <- er_int %>%
  separate(sample_id, c("fraction", "sample-rep"), "_")

```


## Prep bulk fraction data
```{r}
# Taking out bad 40's (retest this sample along with #60)
er_bulk_ed <- er_bulk_ed[-c(1, 12), ]

# Separate "sample-rep"
er_bulk_ed <- er_bulk_ed %>%
  separate(sample_id_corrected, c("ID", "rep"), "-")

ggplot(er_bulk_ed) +
  aes(x=ID, y=C_wt_pct, color=rep) +
  geom_point()

# Average the sample reps
er_bulk_av <- er_bulk_ed %>%
  group_by(ID) %>%
  summarize(C_mean = mean(C_wt_pct), N_mean = mean(N_wt_pct), C_sd = sd(C_wt_pct), N_sd = sd(N_wt_pct))

# Read in sample key
sample_key <- read.csv("Data/June2017_EastRiver_samplekey.csv")

# Separate the "sample" column into two separate columns (location, rep)
sample_key <- sample_key %>%
  separate(sample, c("location", "rep"), "-")

# Separate the "depth_cm" column into two separate columns (top_cm, btm_cm)
sample_key <- sample_key %>%
  separate(depth_cm, c("top_cm", "btm_cm"), "-")

# Remove "b" from rep column
sample_key$rep <- gsub("[^0-9\\.]", "", sample_key$rep)
#sample_key$location <- gsub("[^0-9\\.]", "", sample_key$location) 

# Convert the soil depths to numeric, so R treats them as numbers (and not characters).
sample_key$top_cm <- as.numeric(sample_key$top_cm)
sample_key$btm_cm <- as.numeric(sample_key$btm_cm)

# Change order
#sample_key <- sample_key[order(sample_key$location, sample_key$rep), ]

# Merge the total CN data with the sample key, using the common column "ID".
total_bulk_cn <- merge(sample_key, er_bulk_av, by="ID")
total_bulk_cn <- total_bulk_cn[order(total_bulk_cn$location, total_bulk_cn$rep, total_bulk_cn$top_cm), ]

#Export as csv
#write.csv(total_bulk_cn, "Data/EA_data/25April2018_EA_bulk_processed.csv")

```



## Prep intermediate fraction data for Marco (March 2018)
```{r}
# take out standards, composite samples, and Evan's data (maybe need to look at composite samples because I didn't have enough intermediate samples to run individuals)
er_int_short <- er_int[c(6:27), ]

# Separate "sample-rep"
er_int_short <- er_int_short %>%
  separate(`sample-rep`, c("ID", "rep"), "-")

# Average the sample reps
er_int_short_test <- er_int_short %>%
  group_by(ID) %>%
  summarize(C_mean = mean(C_wt_pct), N_mean = mean(N_wt_pct), C_sd = sd(C_wt_pct), N_sd = sd(N_wt_pct))

# Merge the total CN data with the sample key, using the common column "ID".
total_int_cn <- merge(sample_key, er_int_short_test, by="ID")
total_int_cn <- total_int_cn[order(total_int_cn$location, total_int_cn$rep, total_int_cn$top_cm), ]

#Export as csv
#write.csv(total_int_cn, "Data/EA_data/25April2018_EA_int_processed.csv")

```


## Prep heavy fraction data for Marco (March 2018)
```{r}
er_heavy_short <- er_heavy

# Separate "sample-rep"
er_heavy_short <- er_heavy_short %>%
  separate(`sample-rep`, c("ID", "rep"), "-")

# Average the sample reps
er_heavy_short_test <- er_heavy_short %>%
  group_by(ID) %>%
  summarize(C_mean = mean(C_wt_pct), N_mean = mean(N_wt_pct), C_sd = sd(C_wt_pct), N_sd = sd(N_wt_pct))


# Merge the total CN data with the sample key, using the common column "ID".
total_heavy_cn <- merge(sample_key, er_heavy_short_test, by="ID")
total_heavy_cn <- total_heavy_cn[order(total_heavy_cn$location, total_heavy_cn$rep, total_heavy_cn$top_cm), ]

#Export as csv
#write.csv(total_heavy_cn, "Data/EA_data/25April2018_EA_heavy_processed.csv")

```


## Merge bulk, intermediate, and heavy fraction total CN (not corrected for fraction of total mass)
```{r}
# Make fraction column
#total_bulk_cn$frac <- "bulk"
#total_int_cn$frac <- "int"
#total_heavy_cn$frac <- "heavy"

# Make C:N column
total_bulk_cn$bulk_CN <- total_bulk_cn$C_mean / total_bulk_cn$N_mean
total_int_cn$int_CN <- total_int_cn$C_mean / total_int_cn$N_mean
total_heavy_cn$heavy_CN <- total_heavy_cn$C_mean / total_heavy_cn$N_mean

# Remove all ID info except "ID", take out SD (will add back later)
total_bulk_cn <- total_bulk_cn[, -c(8:9)] #leave in the sample location info in this one
total_int_cn <- total_int_cn[, -c(2:5,8:9)]
total_heavy_cn <- total_heavy_cn[, -c(2:5,8:9)]

# rbind
#total_cn <- rbind(total_bulk_cn, total_int_cn, total_heavy_cn)

# Amend the column headers
colnames(total_bulk_cn)[c(6:7)] <- c("bulk_C", "bulk_N")
colnames(total_int_cn)[c(2:3)] <- c("int_C", "int_N")
colnames(total_heavy_cn)[c(2:3)] <- c("heavy_C", "heavy_N")

# Merge by ID
total_cn <- merge(total_bulk_cn, total_int_cn, by="ID", all=TRUE)
total_cn <- merge(total_cn, total_heavy_cn, by="ID", all=TRUE)

total_cn <- total_cn[order(total_cn$location, total_cn$rep, total_cn$top_cm), ]


# Export as csv
#write.csv(total_cn, "Data/EA_data/25April2018_EA_total_cn_processed.csv")



# Melt by frac
#total_bulk_cn_melt <- melt(total_bulk_cn)
#total_int_cn_melt <- melt(total_int_cn)
#total_heavy_cn_melt <- melt(total_heavy_cn)

# rbind
#total_cn <- rbind(total_bulk_cn_melt, total_int_cn_melt, total_heavy_cn_melt)

# Import composite data
comp <- read_excel("October2017_EastRiver_CLS_sampleIDlist.xlsx")[-c(5,7,9, 25:66), -c(2,5:11)]
colnames(comp)[c(1,3)] <- c("sample_label", "ID")

comp$sample_label <- na.locf(comp$sample_label)
comp$location <- na.locf(comp$location)

comp <- comp %>%
  separate(sample_label, c("number", "frac", "comp"), "-")

comp$sample_label <- paste(comp$number, comp$comp, sep="-")

comp <- comp[, -c(1:3)]
colnames(comp)[1] <- "location_title"

# Merge with composite data
total_cn_comp <- merge(total_cn, comp, by="ID")

# Average by comp
total_cn_comp_av <- total_cn_comp %>%
  group_by(sample_label, location_title) %>%
  summarize(
    bulk_C = mean(bulk_C), bulk_N = mean(bulk_N), bulk_CN = mean(bulk_CN),
    int_C = mean(int_C, na.rm=TRUE), int_N = mean(int_N, na.rm=TRUE), int_CN = mean(int_CN, na.rm=TRUE),
    heavy_C = mean(heavy_C), heavy_N = mean(heavy_N), heavy_CN = mean(heavy_CN))

# Export as csv
#write.csv(total_cn_comp_av, "Data/EA_data/25April2018_EA_total_cn_comp_processed.csv")

```


## Corrected CN in intermediate and heavy fractions, as fraction of total mass
```{r}

# First, run EastRiver_densityfrac.rmd script

# INTERMEDIATE FRACTION
# Merge intermediate fraction CN data with density fraction data frame
test_int <- merge(er_int_short_test, dens.frac.merge, by="ID")

# Calculate %C by mass fraction
test_int$C_per_by_mass <- test_int$C_mean * test_int$int_frac_per
test_int$N_per_by_mass <- test_int$N_mean * test_int$int_frac_per
test_int$CN_by_mass <- test_int$C_per_by_mass / test_int$N_per_by_mass

ggplot(test_int) +
  aes(x=mean.depth_cm, y=C_per_by_mass) +
  geom_point() +
  xlab("soil depth (cm)") + ylab("%C by mass fraction") + ggtitle("Intermediate fraction")

# Get only relevant columns
test_int_short <- test_int[, c(1, 18:20)]

# HEAVY FRACTION
# Merge heavy fraction CN data with density fraction data frame
test_heavy <- merge(er_heavy_short_test, dens.frac.merge, by="ID")

# Calculate %C by mass fraction
test_heavy$C_per_by_mass <- test_heavy$C_mean * test_heavy$heavy_frac_per
test_heavy$N_per_by_mass <- test_heavy$N_mean * test_heavy$int_frac_per
test_heavy$CN_by_mass <- test_heavy$C_per_by_mass / test_heavy$N_per_by_mass

# Figure
ggplot(test_heavy) +
  aes(x=mean.depth_cm, y=C_per_by_mass) +
  geom_point()+
  xlab("soil depth (cm)") + ylab("%C by mass fraction") + ggtitle("Heavy fraction")

# Get only relevant columns
test_heavy_short <- test_heavy[, c(1, 10:13, 18:20)]


# Make summary tables as above

# 1. As individual samples
# Amend the column headers
colnames(test_int_short)[c(2:4)] <- c("int_C_massfrac", "int_N_massfrac", "int_CN_massfrac")
colnames(test_heavy_short)[c(6:8)] <- c("heavy_C_massfrac", "heavy_N_massfrac", "heavy_CN_massfrac")

# Merge by ID
total_cn_massfrac <- merge(test_int_short, test_heavy_short, by="ID", all=TRUE)
#total_cn_massfrac <- total_cn_massfrac[order(total_cn_massfrac$location.y, total_cn_massfrac$bottom.y, total_cn_massfrac$rep.y) ,]

# Remove "b" from rep column
total_cn_massfrac$rep <- gsub("[^0-9\\.]", "", total_cn_massfrac$rep)
total_cn_massfrac <- total_cn_massfrac[order(total_cn_massfrac$location, total_cn_massfrac$rep, total_cn_massfrac$top), ]


# Export as csv
#write.csv(total_cn_massfrac, "Data/EA_data/25April2018_EA_total_cn_massfrac_processed.csv")

# 2. As composite samples
# Merge with composite data
total_cn_massfrac_comp <- merge(total_cn_massfrac, comp, by="ID")

# Average by comp
total_cn_massfrac_comp_av <- total_cn_massfrac_comp %>%
  group_by(sample_label, location_title) %>%
  summarize(
#    bulk_C = mean(bulk_C), bulk_N = mean(bulk_N), bulk_CN = mean(bulk_CN),
    int_C_massfrac = mean(int_C_massfrac, na.rm=TRUE), int_N_massfrac = mean(int_N_massfrac, na.rm=TRUE), int_CN_massfrac = mean(int_CN_massfrac, na.rm=TRUE),
    heavy_C_massfrac = mean(heavy_C_massfrac), heavy_N_massfrac = mean(heavy_N_massfrac), heavy_CN_massfrac = mean(heavy_CN_massfrac))

# Export as csv
#write.csv(total_cn_massfrac_comp_av, "Data/EA_data/25April2018_EA_total_cn_massfrac_comp_processed.csv")



```